<h1 id="properties-of-utility-functions">A.2 Properties of Utility
Functions</h1>
<p><strong>Overview.</strong> In this section, we will formalize our
understanding of utility functions. First, we will introduce
<em>Bernoulli utility functions</em>, which are simple utility functions
that allow an agent to select between different choices with known
outcomes. Then we will discuss <em>von Neumann-Morgenstern utility
functions</em>, which model how rational agents select between choices
with probabilistic outcomes based on the concept of <em>expected
utility</em>, to make these tools more generally applicable to the
choices under uncertainty. Finally, we will describe a solution to a
famous puzzle applying expected utility—the <em>St. Petersburg
Paradox</em>—to see why expected utility is a useful tool for decision
making.<p>
Establishing these mathematical foundations will help us understand how
to apply utility functions to various actors and situations.</p>
<h2 id="bernoulli-utility-functions">A.2.1 Bernoulli Utility Functions</h2>
<p><strong>Bernoulli utility functions represent an individual’s
preferences over potential outcomes.</strong> Suppose we give people the
choice between an apple, a banana, and a cherry. If we already know each
person’s utility function, we can deduce, predict, and compare their
preferences In the introduction, we met Alice, whose preferences are
represented by the utility function over fruits:<p>
<span
class="math display"><em>u</em>(<em>f</em>) = 12<em>a</em> + 10<em>b</em> + 2<em>c</em>.</span>
This is a Bernoulli utility function.</p>
<p><strong>Bernoulli utility functions can be used to convey the
strength of preferences across opportunities.</strong> In their most
basic form, Bernoulli utility functions express ordinal preferences by
ranking options in order of desirability. For more information, we can
consider cardinal representations of preferences. With cardinal utility
functions, numbers matter: while the units are still arbitrary, the
relative differences are informative.<p>
To illustrate the difference between ordinal and cardinal comparisons,
consider how we talk about temperature. When we want to precisely convey
information about temperature, we use a cardinal measure like Celsius or
Fahrenheit: “Today is five degrees warmer than yesterday.” We could have
also accurately, but less descriptively, used an ordinal descriptor:
“Today is warmer than yesterday.” Similarly, if we interpret Alice’s
utility function as cardinal, we can conclude that she feels more
strongly about the difference between a banana and a cherry (8 units of
utility) than she does about the difference between an apple and a
banana (2 units). We can gauge the relative strength of Alice’s
preferences from a utility function.</p>
<h2 id="von-neumann-morgenstern-utility-functions">A.2.2 Von
Neumann-Morgenstern Utility Functions</h2>
<p><strong>Von Neumann-Morgenstern utility functions help us understand
what people prefer when outcomes are uncertain.</strong> We do not yet
know how Alice values an uncertain situation, such as a coin flip. If
the coin lands on heads, Alice gets both a banana and an apple. But if
it lands on tails, she gets nothing. Now let’s say we give Alice a
choice between getting an apple, getting a banana, or flipping the coin.
Since we know her fruit Bernoulli utility function, we know her
preferences between apples and bananas, but we do not know how she
compares each fruit to the coin flip. We’d like to convert the possible
outcomes of the coin flip into a number that represents the utility of
each outcome, which can then be compared directly against the utility of
receiving the fruits with certainty. The von Neumann-Morgenstern (vNM)
utility functions help us do this <span class="citation"
data-cites="vonneumann1947theory">[1]</span>. They are extensions of
Bernoulli utility functions, and work specifically for situations with
uncertainty, represented as <em>lotteries</em> (denoted <strong><span
class="math inline"><em>L</em></span></strong>), like this coin flip.
First, we work through some definitions and assumptions that allow us to
construct utility functions over potential outcomes, and then we explore
the relation between von Neumann-Morgenstern utility functions and
expected utility.</p>
<p><strong>A lottery assigns a probability to each possible
outcome.</strong> Formally, a lottery <span
class="math inline"><em>L</em></span> is any set of possible outcomes,
denoted <span
class="math inline"><em>o</em><sub><em>i</em></sub></span>, and their
associated probabilities, denoted <span
class="math inline"><em>p</em><sub><em>i</em></sub></span>. Consider a
simple lottery: a coin flip where Alice receives an apple on heads, and
a banana on tails. This lottery has possible outcomes <span
class="math inline"><em>a</em><em>p</em><em>p</em><em>l</em><em>e</em></span>
and <span
class="math inline"><em>b</em><em>a</em><em>n</em><em>a</em><em>n</em><em>a</em></span>,
each with probability <span class="math inline">0.5</span>. If a
different lottery offers a cherry with certainty, it would have only the
possible outcome <span
class="math inline"><em>c</em><em>h</em><em>e</em><em>r</em><em>r</em><em>y</em></span>
with probability <span class="math inline">1</span>. Objective
probabilities are used when the probabilities are known, such as when
calculating the probability of winning in casino games like roulette. In
other cases where objective probabilities are not known, like predicting
the outcome of an election, an individual’s subjective best-guess could
be used instead. So, both uncertain and certain outcomes can be
represented by lotteries.<p>
</p>
<div class="storybox">
<p><span>A Note on Expected Value vs. Expected Utility</span></p>
<p>An essential distinction in this chapter is that between expected
value and expected utility.</p>
<p><strong>Expected value is the average outcome of a random
event.</strong> While most lottery tickets have negative expected value,
in rare circumstances they have positive expected value. Suppose a
lottery has a jackpot of 1 billion dollars. Let the probability of
winning the jackpot be 1 in 300 million, and let the price of a lottery
ticket be $2. Then the expected value is calculated by adding together
each possible outcome by its probability of occurrence. The two outcomes
are (1) that we win a billion dollars, minus the cost of $2 to play the
lottery, which happens with probability one in 300 million, and (2) that
we are $2 in debt. We can calculate the expected value with the formula:
<span class="math display">$$\frac{1}{300 \text{ million}} \cdot
\left(\$ 1 \text{ billion}-\$ 2\right)+\left(1-\frac{1}{300 \text{
million}}\right) \cdot \left(-\$ 2\right)\approx \$ 1.33.$$</span> The
expected value of the lottery ticket is positive, meaning that, on
average, buying the lottery ticket would result in us receiving <span
class="math inline">$</span>1.33.<p>
Generally, we can calculate expected value by multiplying each outcome
value, <span class="math inline"><em>o</em><em>i</em></span>, with its
probability <span class="math inline"><em>p</em>,</span> and sum
everything up over all <span class="math inline"><em>n</em></span>
possibilities: <span
class="math display"><em>E</em>[<em>L</em>] = <em>o</em><sub>1</sub> ⋅ <em>p</em><sub>1</sub> + <em>o</em><sub>2</sub> ⋅ <em>p</em><sub>2</sub> +  ⋅ <em>s</em> + <em>o</em><sub><em>n</em></sub>·<sub><em>n</em></sub>.</span>
<strong>Expected utility is the average utility of a random
event.</strong> Although the lottery has positive expected value, buying
a lottery ticket may still not increase its expected utility. Expected
utility is distinct from expected value: instead of summing over the
monetary outcomes (weighing each outcome by its probability), we sum
over the utility the agent receives from each outcome (weighing each
outcome by its probability).<p>
If the agent’s utility function indicates that one “util” is just as
valuable as one dollar, that is <span
class="math inline"><em>u</em>($<em>x</em>) = <em>x</em></span>, then
expected utility and expected value would be the same. But suppose the
agent’s utility function were a different function, such as <span
class="math inline"><em>u</em>($<em>x</em>) = <em>x</em><sup>1/3</sup></span>.
This utility function means that the agent values each additional dollar
less and less as they have more and more money.<p>
For example, if an agent with this utility function already has <span
class="math inline">$</span>500, an extra dollar would increase their
utility by 0.05, but if they already have <span
class="math inline">$</span>200,000, an extra dollar would increase
their utility by only 0.0001. With this utility function, the expected
utility of this lottery example is negative: <span
class="math display">$$\frac{1}{300 \text{ million}} \cdot \left(1
\text{ billion}-2\right)^{1/3}+\left(1-\frac{1}{300 \text{
million}}\right) \cdot \left(-2\right)^{1/3}\approx -1.26.$$</span>
Consequently, expected value can be positive while expected utility can
be negative, so the two concepts are distinct.<p>
Generally, expected utility is calculated as: <span
class="math display"><em>E</em>[<em>u</em>(<em>L</em>)] = <em>u</em>(<em>o</em><sub>1</sub>) ⋅ <em>p</em><sub>1</sub> + <em>u</em>(<em>o</em><sub>2</sub>) ⋅ <em>p</em><sub>2</sub> + ⋯ + <em>u</em>(<em>o</em><sub><em>n</em></sub>) ⋅ <em>p</em><sub><em>n</em></sub>.</span></p>
</div>
<p><strong>According to expected utility theory, rational agents make
decisions that maximize expected utility.</strong> Von Neumann and
Morgenstern proposed a set of basic propositions called <em>axioms</em>
that define an agent with rational preferences. When an agent satisfies
these axioms, their preferences can be represented by a von
Neumann-Morgenstern utility function, which is equivalent to using
expected utility to make decisions. While expected utility theory is
often used to model human behavior, it is important to note that it is
an imperfect approximation. In the final section of this chapter, we
present some criticisms of expected utility theory and the vNM
rationality axioms as they apply to humans. However, artificial agents
might be designed along these lines, resulting in an explicit expected
utility maximizer, or something approximating an expected utility
maximizer. The von Neumann-Morgenstern rationality axioms are listed
below with mathematically precise notation for sake of completeness, but
a technical understanding of them is not necessary to proceed with the
chapter.</p>
<p><strong>Von Neumann-Morgenstern Rationality Axioms.</strong> When the
following axioms are satisfied, we can assume a utility function of an
expected utility form, where agents prefer lotteries that have higher
expected utility <span class="citation"
data-cites="vonneumann1947theory">[1]</span>. <span
class="math inline"><em>L</em></span> is a lottery. <span
class="math inline"><em>L</em><sub><em>A</em></sub> ≽ <em>L</em><sub><em>B</em></sub></span>
means that the agent prefers lottery A to lottery B, whereas <span
class="math inline"><em>L</em><sub><em>A</em></sub> ∼ <em>L</em><sub><em>B</em></sub></span>
means that the agent is indifferent between lottery A and lottery B.
These axioms and conclusions that can be derived from them are
contentious, as we will see later on in this chapter. There are six such
axioms, that we can split into two groups.<p>
The first two axioms may seem obvious, but are nonetheless
essential:</p>
<ol>
<li><p><span>Monotonicity</span>: Agents prefer higher probabilities of
preferred outcomes.</p></li>
<li><p><span>Decomposability</span>: The agent is indifferent between
two lotteries that share the same probabilities for all the same
outcomes, even if they are described differently.</p></li>
</ol>
<p><strong></strong> The remaining four axioms are:</p>
<ol>
<li><p>Completeness: The agent can rank their preferences over all
lotteries. For any two lotteries, it must be that <span
class="math inline"><em>L</em><sub><em>A</em></sub> ≽ <em>L</em><sub><em>B</em></sub></span>
or <span
class="math inline"><em>L</em><sub><em>B</em></sub> ≽ <em>L</em><sub><em>A</em></sub></span>.</p></li>
<li><p>Transitivity: If <span
class="math inline"><em>L</em><sub><em>A</em></sub> ≽ <em>L</em><sub><em>B</em></sub></span>
and <span
class="math inline"><em>L</em><sub><em>B</em></sub> ≽ <em>L</em><sub><em>C</em></sub></span>,
then <span
class="math inline"><em>L</em><sub><em>A</em></sub> ≽ <em>L</em><sub><em>C</em></sub></span>.</p></li>
<li><p>Continuity: For any three lotteries, <span
class="math inline"><em>L</em><sub><em>A</em></sub> ≽ <em>L</em><sub><em>B</em></sub> ≽ <em>L</em><sub><em>C</em></sub></span>,
there exists a probability <span
class="math inline"><em>p</em> ∈ [0,1]</span> such that <span
class="math inline"><em>p</em><em>L</em><sub><em>A</em></sub> + (1−<em>p</em>)<em>L</em><sub><em>C</em></sub> ∼ <em>L</em><sub><em>B</em></sub></span>.
This means that the agent is indifferent between <span
class="math inline"><em>L</em><sub><em>B</em></sub></span> and some
combination of the worse lottery <span
class="math inline"><em>L</em><sub><em>C</em></sub></span> and the
better lottery <span
class="math inline"><em>L</em><sub><em>A</em></sub></span>. In practice,
this means that agents’ preferences change smoothly and predictably with
changes in options.</p></li>
<li><p>Independence: The preference between two lotteries is not
impacted by the addition of equal probabilities of a third, independent
lottery to each lottery. That is, <span
class="math inline"><em>L</em><sub><em>A</em></sub> ≽ <em>L</em><sub><em>B</em></sub></span>
is equivalent to <span
class="math inline"><em>p</em><em>L</em><sub><em>A</em></sub> + (1−<em>p</em>)<em>L</em><sub><em>C</em></sub> ≽ <em>p</em><em>L</em><sub><em>B</em></sub> + (1−<em>p</em>)<em>L</em><sub><em>C</em></sub></span>
for any <span
class="math inline"><em>L</em><sub><em>C</em></sub></span>.
&gt;</p></li>
</ol>
<p><strong>Form of von Neumann-Morgenstern utility functions.</strong>
If an agent’s preferences are consistent with the above axioms, their
preferences can be represented by a vNM utility function. This utility
function, denoted by a capital <span
class="math inline"><em>U</em></span>, is simply the expected Bernoulli
utility of a lottery. That is, a vNM utility function takes the
Bernoulli utility of each outcome, multiplies each with its
corresponding probability of occurrence, and then adds everything up.
Formally, an agent’s expected utility for a lottery <span
class="math inline"><em>L</em></span> is calculated as: <span
class="math display"><em>U</em>(<em>L</em>) = <em>u</em>(<em>o</em><sub>1</sub>) ⋅ <em>p</em><sub>1</sub> + <em>u</em>(<em>o</em><sub>2</sub>) ⋅ <em>p</em><sub>2</sub> + ⋯ + <em>u</em>(<em>o</em><sub><em>n</em></sub>) ⋅ <em>p</em><sub><em>n</em></sub>,</span>
so expected utility can be thought of as a weighted average of the
utilities of different outcomes.<p>
This is identical to the expected utility formula we discussed above—we
sum over the utilities of all the possible outcomes, each multiplied by
its probability of occurrence. With Bernoulli utility functions, an
agent prefers <span class="math inline"><em>a</em></span> to <span
class="math inline"><em>b</em></span> if and only if their utility from
receiving <span class="math inline"><em>a</em></span> is greater than
their utility from receiving <span
class="math inline"><em>b</em></span>. With expected utility, an agent
prefers lottery <span
class="math inline"><em>L</em><sub><em>A</em></sub></span> to lottery
<span class="math inline"><em>L</em><sub><em>B</em></sub></span> if and
only if their expected utility from lottery <span
class="math inline"><em>L</em><sub><em>A</em></sub></span> is greater
than from lottery <span
class="math inline"><em>L</em><sub><em>B</em></sub></span>. That is:
<span
class="math display"><em>L</em><sub><em>A</em></sub> ≻ <em>L</em><sub><em>B</em></sub> ⇔ <em>U</em>(<em>L</em><sub><em>A</em></sub>) &gt; <em>U</em>(<em>L</em><sub><em>B</em></sub>).</span>
where the symbol <span class="math inline">≻</span> indicates
preference. The von Neumann-Morgenstern utility function models the
decision making of an agent considering two lotteries as just
calculating the expected utilities and choosing the larger resulting
one.<p>
</p>
<div class="storybox">
<p><span>A Note on Logarithms</span></p>
<p><strong>Logarithmic functions are commonly used as utility
functions.</strong> A logarithm is a mathematical function that
expresses the power to which a given number (referred to as the base)
must be raised in order to produce a value. The logarithm of a number
<span class="math inline"><em>x</em></span> with respect to base <span
class="math inline"><em>b</em></span> is denoted as <span
class="math inline">log<sub><em>b</em></sub><em>x</em></span>, and is
the exponent to which <span class="math inline"><em>b</em></span> must
be raised to produce the value <span
class="math inline"><em>x</em></span>. For example, <span
class="math inline">log<sub>2</sub>8 = 3</span>, because <span
class="math inline">2<sup>3</sup> = 8</span>.<p>
One special case of the logarithmic function, the natural logarithm, has
a base of <span class="math inline"><em>e</em></span> (which is Euler’s
constant, roughly 2.718); in this chapter, it is referred to simply as
<span class="math inline">log </span>. Logarithms have the following
properties, independent of base: <span
class="math inline">log 0 →  − ∞</span>, <span
class="math inline">log 1 = 0,</span> <span
class="math inline">log<sub><em>b</em></sub><em>b</em> = 1,</span> and
<span
class="math inline">log<sub><em>b</em></sub><em>b</em><sup><em>a</em></sup> = <em>a</em></span>.<p>
Logarithms have a downward, concave shape, meaning the output increases
slower than the input. This shape resembles how humans value resources:
we generally value a good less if we already have more of it.
Logarithmic functions value goods in inverse proportion to how much of
the resource we already have.<p>
</p>
</div>
<h2 id="st.-petersburg-paradox">A.2.3 St. Petersburg Paradox</h2>
<p>An old man on the streets of St. Petersburg offers gamblers the
following game: he will flip a fair coin repeatedly until it lands on
tails. If the first flip lands tails, the game ends and the pension fund
gets $2. If the coin first lands on heads and then lands on tails, the
game ends and the gambler gets $4. The amount of money (the “return”)
will double for each consecutive flip landing heads before the coin
ultimately lands tails. The game concludes when the coin first lands
tails, and the gambler receives the appropriate returns. Now, the
question is, how much should a gambler be willing to pay from the
pension fund to play this game <span class="citation"
data-cites="peterson2019paradox">[2]</span>?<p>
With probability <span class="math inline">$\frac{1}{2}$</span>, the
first toss will land on tails, in which case the gambler wins two
dollars. With probability <span
class="math inline">$\frac{1}{4}$</span>, the first toss lands heads and
the second lands tails, and the gambler wins four dollars.
Extrapolating, this game offers a maximum possible payout of: <span
class="math display">$$\$ 2^{n} = \$ \overbrace{2 \cdot 2 \cdot 2\cdots
2 \cdot 2 \cdot 2}^{n \text{ times}},$$</span> where <span
class="math inline"><em>n</em></span> is the number of flips until and
including when the coin lands on tails. As offered, though, there is no
limit to the size of <span class="math inline"><em>n</em></span>, since
the company promises to keep flipping the coin until it lands on tails.
The expected payout of this game is therefore: <span
class="math display">$$E\left[L\right] =\frac{1}{2} \cdot \$
2+\frac{1}{4} \cdot \$ 4+\frac{1}{8} \cdot \$ 8+\cdots  = \$ 1+\$ 1+\$
1+\cdots  = \$ \infty.$$</span> Bernoulli described this situation as a
paradox because he believed that, despite it having infinite expected
value, anyone would take a large but finite amount of money over the
chance to play the game. While paying <span
class="math inline">$</span>10,000,000 to play this game would not be
inconsistent with its expected value, we would think it highly
irresponsible! The paradox reveals a disparity between expected value
calculations and reasonable human behavior.<p>
</p>
<p><strong>Logarithmic utility functions can represent decreasing
marginal utility.</strong> A number of ways have been proposed to
resolve the St. Petersburg paradox. We will focus on the most popular:
representing the player with a utility function instead of merely
calculating expected value. As we discussed in the previous section, a
logarithmic utility function seems to resemble how humans think about
wealth. As a person becomes richer, each additional dollar gives them
less satisfaction than before. This concept, called decreasing marginal
utility, makes sense intuitively: a billionaire would not be as
satisfied winning $1000 as someone with significantly less money.
Wealth, and many other resources like food, have such diminishing
returns. While a first slice of pizza is incredibly satisfying, a second
one is slightly less so, and few people would continue eating to enjoy a
tenth slice of pizza.<p>
Assuming an agent with a utility function <span
class="math inline"><em>u</em>($<em>x</em>) = log<sub>2</sub>(<em>x</em>)</span>
over <span class="math inline"><em>x</em></span> dollars, we can
calculate the expected utility of playing the St. Petersburg game as:
<span class="math display">$$E\left[U\left(L\right)\right] =\frac{1}{2}
\cdot \log_{2}(2)+\frac{1}{4} \cdot \log_{2}(4)+\frac{1}{8} \cdot
\log_{2}(8)+\cdots  = 2.$$</span> That is, the expected utility of the
game is 2. From the logarithmic utility function over wealth, we know
that: <span
class="math display">2 = log<sub>2</sub><em>x</em> ⇒ <em>x</em> = 4,</span>
which implies that the player is indifferent between playing this game
and having $4: the level of wealth that gives them the same utility as
what they expect playing the lottery.</p>
<p><strong>Expected utility is more reasonable than expected
value.</strong> The previous calculation explains why an agent with
<span
class="math inline"><em>u</em>($<em>x</em>) = log<sub>2</sub><em>x</em></span>
should not pay large amounts of money to play the St. Petersburg game.
The log utility function implies that the player receives diminishing
returns to wealth, and cares less about situations with small chances of
winning huge sums of money. Figure 5 shows how the large payoffs with
small probability, despite having the same expected value, contribute
little to expected utility. This feature captures the human tendency
towards risk aversion, explored in the next section. Note that while
logarithmic utility functions are a useful model (especially in
resolving such paradoxes), they do not perfectly describe human behavior
across choices, such as the tendency to buy lottery tickets, which we
will explore in the next chapter.<p>
</p>
<p><strong>Summary.</strong> In this section, we examined the properties
of Bernoulli utility functions, which allow us to compare an agent’s
preferences across different outcomes. We then introduced von
Neumann-Morgenstern utility functions, which calculate the average, or
expected, utility over different possible outcomes. From there, we
derived the idea that rational agents are able to make decisions that
maximize expected utility. Through the St. Petersburg Paradox, we showed
that taking the expected utility of a logarithmic function leads to more
reasonable behavior. Having understood some properties of utility
functions, we can now examine the problem of incorrigibility, where AI
systems do not accept corrective interventions because of rigid
preferences.</p>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0"
role="list">
<div id="ref-vonneumann1947theory" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] J.
V. Neumann and O. Morgenstern, <em>Theory of games and economic
behavior</em>. Princeton University Press, 1947.</div>
</div>
<div id="ref-peterson2019paradox" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] M.
Peterson, <span>“<span>The St. Petersburg Paradox</span>,”</span> in
<em>The <span>Stanford</span> encyclopedia of philosophy</em>,
<span>F</span>all 2023., E. N. Zalta and U. Nodelman, Eds., <a
href="https://plato.stanford.edu/archives/fall2023/entries/paradox-stpetersburg/"
class="uri">https://plato.stanford.edu/archives/fall2023/entries/paradox-stpetersburg/</a>;
Metaphysics Research Lab, Stanford University, 2023.</div>
</div>
</div>
