<h1 id="properties-of-utility-functions"> Properties of Utility
Functions</h1>
<p><strong>Overview.</strong> In this section, we will formalize our
understanding of utility functions. First, we will introduce
<em>Bernoulli utility functions</em>, which are simple utility functions
that allow an agent to select between different choices with known
outcomes. Then we will discuss <em>von Neumann-Morgenstern utility
functions</em>, which model how rational agents select between choices
with probabilistic outcomes based on the concept of <em>expected
utility</em>, to make these tools more generally applicable to the
choices under uncertainty. Finally, we will describe a solution to a
famous puzzle applying expected utility—the <em>St. Petersburg
Paradox</em>—to see why expected utility is a useful tool for decision
making.</p>
<p>Establishing these mathematical foundations will help us understand
how to apply utility functions to various actors and situations.</p>
<h2 id="bernoulli-utility-functions"> Bernoulli Utility
Functions</h2>
<p><strong>Bernoulli utility functions represent an individual’s
preferences over potential outcomes.</strong> Suppose we give people the
choice between an apple, a banana, and a cherry. If we already know each
person’s utility function, we can deduce, predict, and compare their
preferences In the introduction, we met <strong></strong>Alice, whose
preferences are represented by the utility function over fruits:<br />
<span class="math display">\[u(f) = 12a+10b+2c.\]</span> This is a
Bernoulli utility function.</p>
<p><strong>Bernoulli utility functions can be used to convey the
strength of preferences across opportunities.</strong> In their most
basic form, Bernoulli utility functions express ordinal preferences by
ranking options in order of desirability. For more information, we can
consider cardinal representations of preferences. With cardinal utility
functions, numbers matter: while the units are still arbitrary, the
relative differences are informative.<br />
To illustrate the difference between ordinal and cardinal comparisons,
consider how we talk about temperature. When we want to precisely convey
information about temperature, we use a cardinal measure like Celsius or
Fahrenheit: “Today is five degrees warmer than yesterday.” We could have
also accurately, but less descriptively, used an ordinal descriptor:
“Today is warmer than yesterday.” Similarly, if we interpret Alice’s
utility function as cardinal, we can conclude that she feels more
strongly about the difference between a banana and a cherry (8 units of
utility) than she does about the difference between an apple and a
banana (2 units). We can gauge the relative strength of Alice’s
preferences from a utility function.</p>
<h2 id="von-neumann-morgenstern-utility-functions"> Von
Neumann-Morgenstern Utility Functions</h2>
<p><strong>Von Neumann-Morgenstern utility functions help us understand
what people prefer when outcomes are uncertain.</strong> We do not yet
know how Alice values an uncertain situation, such as a coin flip. If
the coin lands on heads, Alice gets both a banana and an apple. But if
it lands on tails, she gets nothing. Now let’s say we give Alice a
choice between getting an apple, getting a banana, or flipping the coin.
Since we know her fruit Bernoulli utility function, we know her
preferences between apples and bananas, but we do not know how she
compares each fruit to the coin flip. We’d like to convert the possible
outcomes of the coin flip into a number that represents the utility of
each outcome, which can then be compared directly against the utility of
receiving the fruits with certainty. The von Neumann-Morgenstern (vNM)
utility functions help us do this <span class="citation"
data-cites="vonneumann1947theory"></span>. They are extensions of
Bernoulli utility functions, and work specifically for situations with
uncertainty, represented as <em>lotteries</em> (denoted <strong><span
class="math inline">\(L\)</span></strong>), like this coin flip. First,
we work through some definitions and assumptions that allow us to
construct utility functions over potential outcomes, and then we explore
the relation between von Neumann-Morgenstern utility functions and
expected utility.</p>
<p><strong>A lottery assigns a probability to each possible
outcome.</strong> Formally, a lottery <span
class="math inline">\(L\)</span> is any set of possible outcomes,
denoted <span class="math inline">\(o_{i}\)</span>, and their associated
probabilities, denoted <span class="math inline">\(p_{i}\)</span>.
Consider a simple lottery: a coin flip where Alice receives an apple on
heads, and a banana on tails. This lottery has possible outcomes <span
class="math inline">\(apple\)</span> and <span
class="math inline">\(banana\)</span>, each with probability <span
class="math inline">\(0.5\)</span>. If a different lottery offers a
cherry with certainty, it would have only the possible outcome <span
class="math inline">\(cherry\)</span> with probability <span
class="math inline">\(1\)</span>. Objective probabilities are used when
the probabilities are known, such as when calculating the probability of
winning in casino games like roulette. In other cases where objective
probabilities are not known, like predicting the outcome of an election,
an individual’s subjective best-guess could be used instead. So, both
uncertain and certain outcomes can be represented by lotteries.<br />
</p>
<div class="storybox">
<p><span>A Note on Expected Value vs. Expected Utility</span></p>
<p>An essential distinction in this chapter is that between expected
value and expected utility.</p>
<p><strong>Expected value is the average outcome of a random
event.</strong> While most lottery tickets have negative expected value,
in rare circumstances they have positive expected value. Suppose a
lottery has a jackpot of 1 billion dollars. Let the probability of
winning the jackpot be 1 in 300 million, and let the price of a lottery
ticket be $2. Then the expected value is calculated by adding together
each possible outcome by its probability of occurrence. The two outcomes
are (1) that we win a billion dollars, minus the cost of $2 to play the
lottery, which happens with probability one in 300 million, and (2) that
we are $2 in debt. We can calculate the expected value with the formula:
<span class="math display">\[\frac{1}{300 \text{ million}} \cdot
\left(\$ 1 \text{ billion}-\$ 2\right)+\left(1-\frac{1}{300 \text{
million}}\right) \cdot \left(-\$ 2\right)\approx \$ 1.33.\]</span> The
expected value of the lottery ticket is positive, meaning that, on
average, buying the lottery ticket would result in us receiving <span
class="math inline">\(\$\)</span>1.33.<br />
Generally, we can calculate expected value by multiplying each outcome
value, <span class="math inline">\(oi\)</span>, with its probability
<span class="math inline">\(p,\)</span> and sum everything up over all
<span class="math inline">\(n\)</span> possibilities: <span
class="math display">\[E\left[L\right] = o_{1} \cdot p_{1}+o_{2} \cdot
p_{2}+\cdot s +o_{n} \cdotp_{n}.\]</span> <strong>Expected utility is
the average utility of a random event.</strong> Although the lottery has
positive expected value, buying a lottery ticket may still not increase
its expected utility. Expected utility is distinct from expected value:
instead of summing over the monetary outcomes (weighing each outcome by
its probability), we sum over the utility the agent receives from each
outcome (weighing each outcome by its probability).<br />
If the agent’s utility function indicates that one “util” is just as
valuable as one dollar, that is <span class="math inline">\(u\left(\$
x\right) = x\)</span>, then expected utility and expected value would be
the same. But suppose the agent’s utility function were a different
function, such as <span class="math inline">\(u\left(\$ x\right) =
x^{1/3}\)</span>. This utility function means that the agent values each
additional dollar less and less as they have more and more money.<br />
For example, if an agent with this utility function already has <span
class="math inline">\(\$\)</span>500, an extra dollar would increase
their utility by 0.05, but if they already have <span
class="math inline">\(\$\)</span>200,000, an extra dollar would increase
their utility by only 0.0001. With this utility function, the expected
utility of this lottery example is negative: <span
class="math display">\[\frac{1}{300 \text{ million}} \cdot \left(1
\text{ billion}-2\right)^{1/3}+\left(1-\frac{1}{300 \text{
million}}\right) \cdot \left(-2\right)^{1/3}\approx -1.26.\]</span>
Consequently, expected value can be positive while expected utility can
be negative, so the two concepts are distinct.<br />
Generally, expected utility is calculated as: <span
class="math display">\[E[u(L)] = u(o_{1}) \cdot p_{1}+u(o_{2}) \cdot
p_{2}+\cdots +u(o_{n}) \cdot p_{n}.\]</span></p>
</div>
<p><strong>According to expected utility theory, rational agents make
decisions that maximize expected utility.</strong> Von Neumann and
Morgenstern proposed a set of basic propositions called <em>axioms</em>
that define an agent with rational preferences. When an agent satisfies
these axioms, their preferences can be represented by a von
Neumann-Morgenstern utility function, which is equivalent to using
expected utility to make decisions. While expected utility theory is
often used to model human behavior, it is important to note that it is
an imperfect approximation. In the final section of this chapter, we
present some criticisms of expected utility theory and the vNM
rationality axioms as they apply to humans. However, artificial agents
might be designed along these lines, resulting in an explicit expected
utility maximizer, or something approximating an expected utility
maximizer. The von Neumann-Morgenstern rationality axioms are listed
below with mathematically precise notation for sake of completeness, but
a technical understanding of them is not necessary to proceed with the
chapter.</p>
<p><strong>Von Neumann-Morgenstern Rationality Axioms.</strong> When the
following axioms are satisfied, we can assume a utility function of an
expected utility form, where agents prefer lotteries that have higher
expected utility <span class="citation"
data-cites="vonneumann1947theory"></span>. <span
class="math inline">\(L\)</span> is a lottery. <span
class="math inline">\(L_{A}\succcurlyeq L_{B}\)</span> means that the
agent prefers lottery A to lottery B, whereas <span
class="math inline">\(L_{A}\sim L_{B}\)</span> means that the agent is
indifferent between lottery A and lottery B. These axioms and
conclusions that can be derived from them are contentious, as we will
see later on in this chapter. There are six such axioms, that we can
split into two groups.<br />
The first two axioms may seem obvious, but are nonetheless
essential:</p>
<ol>
<li><p><span>Monotonicity</span>: Agents prefer higher probabilities of
preferred outcomes.</p></li>
<li><p><span>Decomposability</span>: The agent is indifferent between
two lotteries that share the same probabilities for all the same
outcomes, even if they are described differently.</p></li>
</ol>
<p><strong></strong> The remaining four axioms are:</p>
<ol>
<li><p>Completeness: The agent can rank their preferences over all
lotteries. For any two lotteries, it must be that <span
class="math inline">\(L_{A}\succcurlyeq L_{B}\)</span> or <span
class="math inline">\(L_{B}\succcurlyeq L_{A}\)</span>.</p></li>
<li><p>Transitivity: If <span class="math inline">\(L_{A}\succcurlyeq
L_{B}\)</span> and <span class="math inline">\(L_{B}\succcurlyeq
L_{C}\)</span>, then <span class="math inline">\(L_{A}\succcurlyeq
L_{C}\)</span>.</p></li>
<li><p>Continuity: For any three lotteries, <span
class="math inline">\(L_{A}\succcurlyeq L_{B}\succcurlyeq
L_{C}\)</span>, there exists a probability <span
class="math inline">\(p\in\left[0,1\right]\)</span> such that <span
class="math inline">\(pL_{A}+\left(1-p\right)L_{C}\sim L_{B}\)</span>.
This means that the agent is indifferent between <span
class="math inline">\(L_{B}\)</span> and some combination of the worse
lottery <span class="math inline">\(L_{C}\)</span> and the better
lottery <span class="math inline">\(L_{A}\)</span>. In practice, this
means that agents’ preferences change smoothly and predictably with
changes in options.</p></li>
<li><p>Independence: The preference between two lotteries is not
impacted by the addition of equal probabilities of a third, independent
lottery to each lottery. That is, <span
class="math inline">\(L_{A}\succcurlyeq L_{B}\)</span> is equivalent to
<span class="math inline">\(pL_{A}+\left(1-p\right)L_{C}\succcurlyeq
pL_{B}+\left(1-p\right)L_{C}\)</span> for any <span
class="math inline">\(L_{C}\)</span>. &gt;</p></li>
</ol>
<p><strong>Form of von Neumann-Morgenstern utility functions.</strong>
If an agent’s preferences are consistent with the above axioms, their
preferences can be represented by a vNM utility function. This utility
function, denoted by a capital <span class="math inline">\(U\)</span>,
is simply the expected Bernoulli utility of a lottery. That is, a vNM
utility function takes the Bernoulli utility of each outcome, multiplies
each with its corresponding probability of occurrence, and then adds
everything up. Formally, an agent’s expected utility for a lottery <span
class="math inline">\(L\)</span> is calculated as: <span
class="math display">\[U\left(L\right) = u\left(o_{1}\right) \cdot
p_{1}+u\left(o_{2}\right) \cdot p_{2}+\cdots +u\left(o_{n}\right) \cdot
p_{n},\]</span> so expected utility can be thought of as a weighted
average of the utilities of different outcomes.<br />
This is identical to the expected utility formula we discussed above—we
sum over the utilities of all the possible outcomes, each multiplied by
its probability of occurrence. With Bernoulli utility functions, an
agent prefers <span class="math inline">\(a\)</span> to <span
class="math inline">\(b\)</span> if and only if their utility from
receiving <span class="math inline">\(a\)</span> is greater than their
utility from receiving <span class="math inline">\(b\)</span>. With
expected utility, an agent prefers lottery <span
class="math inline">\(L_{A}\)</span> to lottery <span
class="math inline">\(L_{B}\)</span> if and only if their expected
utility from lottery <span class="math inline">\(L_{A}\)</span> is
greater than from lottery <span class="math inline">\(L_{B}\)</span>.
That is: <span class="math display">\[L_{A}\succ L_{B}\Leftrightarrow
U\left(L_{A}\right)&gt;U\left(L_{B}\right).\]</span> where the symbol
<span class="math inline">\(\succ\)</span> indicates preference. The von
Neumann-Morgenstern utility function models the decision making of an
agent considering two lotteries as just calculating the expected
utilities and choosing the larger resulting one.<br />
</p>
<div class="storybox">
<p><span>A Note on Logarithms</span></p>
<p><strong>Logarithmic functions are commonly used as utility
functions.</strong> A logarithm is a mathematical function that
expresses the power to which a given number (referred to as the base)
must be raised in order to produce a value. The logarithm of a number
<span class="math inline">\(x\)</span> with respect to base <span
class="math inline">\(b\)</span> is denoted as <span
class="math inline">\(\log_{b}x\)</span>, and is the exponent to which
<span class="math inline">\(b\)</span> must be raised to produce the
value <span class="math inline">\(x\)</span>. For example, <span
class="math inline">\(\log_{2}8 = 3\)</span>, because <span
class="math inline">\(2^{3} = 8\)</span>.<br />
One special case of the logarithmic function, the natural logarithm, has
a base of <span class="math inline">\(e\)</span> (which is Euler’s
constant, roughly 2.718); in this chapter, it is referred to simply as
<span class="math inline">\(\log\)</span>. Logarithms have the following
properties, independent of base: <span
class="math inline">\(\log0\rightarrow -\infty\)</span>, <span
class="math inline">\(\log1 = 0,\)</span> <span
class="math inline">\(\log_{b}b = 1,\)</span> and <span
class="math inline">\(\log_{b}b^{a} = a\)</span>.<br />
Logarithms have a downward, concave shape, meaning the output increases
slower than the input. This shape resembles how humans value resources:
we generally value a good less if we already have more of it.
Logarithmic functions value goods in inverse proportion to how much of
the resource we already have.<br />
</p>
<figure>

</figure>
</div>
<h2 id="st.-petersburg-paradox"> St. Petersburg Paradox</h2>
<p>An old man on the streets of St. Petersburg offers gamblers the
following game: he will flip a fair coin repeatedly until it lands on
tails. If the first flip lands tails, the game ends and the pension fund
gets $2. If the coin first lands on heads and then lands on tails, the
game ends and the gambler gets $4. The amount of money (the “return”)
will double for each consecutive flip landing heads before the coin
ultimately lands tails. The game concludes when the coin first lands
tails, and the gambler receives the appropriate returns. Now, the
question is, how much should a gambler be willing to pay from the
pension fund to play this game <span class="citation"
data-cites="peterson2019paradox"></span>?<br />
With probability <span class="math inline">\(\frac{1}{2}\)</span>, the
first toss will land on tails, in which case the gambler wins two
dollars. With probability <span
class="math inline">\(\frac{1}{4}\)</span>, the first toss lands heads
and the second lands tails, and the gambler wins four dollars.
Extrapolating, this game offers a maximum possible payout of: <span
class="math display">\[\$ 2^{n} = \$ \overbrace{2 \cdot 2 \cdot 2\cdots
2 \cdot 2 \cdot 2}^{n \text{ times}},\]</span> where <span
class="math inline">\(n\)</span> is the number of flips until and
including when the coin lands on tails. As offered, though, there is no
limit to the size of <span class="math inline">\(n\)</span>, since the
company promises to keep flipping the coin until it lands on tails. The
expected payout of this game is therefore: <span
class="math display">\[E\left[L\right] =\frac{1}{2} \cdot \$
2+\frac{1}{4} \cdot \$ 4+\frac{1}{8} \cdot \$ 8+\cdots  = \$ 1+\$ 1+\$
1+\cdots  = \$ \infty.\]</span> Bernoulli described this situation as a
paradox because he believed that, despite it having infinite expected
value, anyone would take a large but finite amount of money over the
chance to play the game. While paying <span
class="math inline">\(\$\)</span>10,000,000 to play this game would not
be inconsistent with its expected value, we would think it highly
irresponsible! The paradox reveals a disparity between expected value
calculations and reasonable human behavior.<br />
</p>
<figure>

</figure>
<p><strong>Logarithmic utility functions can represent decreasing
marginal utility.</strong> A number of ways have been proposed to
resolve the St. Petersburg paradox. We will focus on the most popular:
representing the player with a utility function instead of merely
calculating expected value. As we discussed in the previous section, a
logarithmic utility function seems to resemble how humans think about
wealth. As a person becomes richer, each additional dollar gives them
less satisfaction than before. This concept, called decreasing marginal
utility, makes sense intuitively: a billionaire would not be as
satisfied winning $1000 as someone with significantly less money.
Wealth, and many other resources like food, have such diminishing
returns. While a first slice of pizza is incredibly satisfying, a second
one is slightly less so, and few people would continue eating to enjoy a
tenth slice of pizza.<br />
Assuming an agent with a utility function <span
class="math inline">\(u(\$ x) = \log_{2}\left(x\right)\)</span> over
<span class="math inline">\(x\)</span> dollars, we can calculate the
expected utility of playing the St. Petersburg game as: <span
class="math display">\[E\left[U\left(L\right)\right] =\frac{1}{2} \cdot
\log_{2}(2)+\frac{1}{4} \cdot \log_{2}(4)+\frac{1}{8} \cdot
\log_{2}(8)+\cdots  = 2.\]</span> That is, the expected utility of the
game is 2. From the logarithmic utility function over wealth, we know
that: <span class="math display">\[2 = \log_{2}x\Rightarrow x =
4,\]</span> which implies that the player is indifferent between playing
this game and having $4: the level of wealth that gives them the same
utility as what they expect playing the lottery.</p>
<p><strong>Expected utility is more reasonable than expected
value.</strong> The previous calculation explains why an agent with
<span class="math inline">\(u\left(\$ x\right) = \log_{2}x\)</span>
should not pay large amounts of money to play the St. Petersburg game.
The log utility function implies that the player receives diminishing
returns to wealth, and cares less about situations with small chances of
winning huge sums of money. Figure 5 shows how the large payoffs with
small probability, despite having the same expected value, contribute
little to expected utility. This feature captures the human tendency
towards risk aversion, explored in the next section. Note that while
logarithmic utility functions are a useful model (especially in
resolving such paradoxes), they do not perfectly describe human behavior
across choices, such as the tendency to buy lottery tickets, which we
will explore in the next chapter.<br />
</p>
<figure>

</figure>
<p><strong>Summary.</strong> In this section, we examined the properties
of Bernoulli utility functions, which allow us to compare an agent’s
preferences across different outcomes. We then introduced von
Neumann-Morgenstern utility functions, which calculate the average, or
expected, utility over different possible outcomes. From there, we
derived the idea that rational agents are able to make decisions that
maximize expected utility. Through the St. Petersburg Paradox, we showed
that taking the expected utility of a logarithmic function leads to more
reasonable behavior. Having understood the properties of utility
functions, we can now examine the problem of incorrigibility, where AI
systems do not accept corrective interventions because of rigid
preferences.</p>
