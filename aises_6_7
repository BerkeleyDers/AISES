<style type="text/css">
    table.tableLayout{
        margin: auto;
        border: 1px solid;
        border-collapse: collapse;
        border-spacing: 1px;
        caption-side: bottom;
    }

    table.tableLayout tr{
        border: 1px solid;
        border-collapse: collapse;
        padding: 5px;
    }

    table.tableLayout th{
        border: 1px solid;
        border-collapse: collapse;
        padding: 3px;
    }

    table.tableLayout td{
        border: 1px solid;
        padding: 5px;
    }
</style>

<h1 id="social-welfare-functions"> 6.7 Social Welfare Functions</h1>
<p><strong>Should we have AIs maximize total wellbeing?</strong> This
section explores the concept of social welfare functions and their
applications in decision-making, especially as applied to AI. Social
welfare functions are one way of moving from the wellbeing of
individuals in a society to a measure of the welfare of the society as a
whole. They are drawn from the disciplines of social choice theory,
welfare economics, and wellbeing science. We begin by defining social
welfare functions and their role in measuring the overall wellbeing of a
society. We then discuss how these functions can be used to compare
different outcomes and guide decision-making by powerful agents such as
governments or beneficial AI. We consider two types of social welfare
functions—-utilitarian and prioritarian—-and consider some of the
advantages and drawbacks of each. By understanding these key concepts,
we can see how how we might design AI to use social welfare functions to
maximize the good they do in society.</p>
<h4
id="social-welfare-functions-are-a-way-to-measure-the-overall-wellbeing-or-happiness-of-a-society.">Social
welfare functions are a way to measure the overall wellbeing or
happiness of a society.</h4>
<p>They aggregate a collection of individual levels of wellbeing into a
single value that represents societal welfare. These functions help us
to understand how to balance individuals’ various needs and interests
within a society. A social welfare function tackles the challenge of
resource and benefit distribution within a community. It assists in
determining how to value one person’s happiness against another’s and
how to weigh the needs of a majority against those of a minority. This
helps solve the <strong>problem of aggregation</strong>: the challenge
of integrating varied individual wellbeing into a single collective
measure that represents the entire society. By expressing societal
welfare in a systematic, numeric manner, social welfare functions
contribute to decisions designed to optimize societal welfare
overall.</p>
<h4
id="different-social-welfare-functions-would-recommend-taking-different-actions.">Different
social welfare functions would recommend taking different actions.</h4>
<p>Consider an AI-powered decision support system used in a city
planning committee. The system suggests three key project proposals for
the betterment of the community: (1) developing a local health clinic,
(2) initiating an after-school education program, and (3) constructing a
community green park. Additionally, it estimates what the wellbeing of
each of the three individuals in this community, Ana, Ben, and Cara,
would be if these proposals were implemented, summarized by their
wellbeing values in the table below.<br />
</p>
<br>
<table class="tableLayout">
<caption>A city planning committee chooses between three projects with
different wellbeing impacts</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Individuals</th>
<th style="text-align: center;">Health Clinic</th>
<th style="text-align: center;">Education Program</th>
<th style="text-align: center;">Green Park</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Ana</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="even">
<td style="text-align: left;">Ben</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Cara</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">10</td>
</tr>
</tbody>
</table>
<br>
<p>None of these options stands out. Each person has a different top
ranking, and none of them would be harmed too much by the planning
committee choosing any one of these. However, a decision must be made.
More generally, we want a systematic rule to move from these individual
data points to a collective ranking. This is where <strong>social
welfare functions</strong> come into play. We can briefly consider two
common approaches that we expand upon later in this section:<br />
</p>
<ol>
<li><p>The <em>utilitarian</em> approach ranks alternatives by the total
wellbeing they bring to all members of society. Using this rule in the
example above, the system would rank the proposals as follows:</p>
<ol>
<li><p>Green Park, where the total wellbeing is <span
class="math inline">3 + 7 + 10 = 20</span>.</p></li>
<li><p>Education Program, where the total wellbeing is <span
class="math inline">8 + 6 + 5 = 19</span>.</p></li>
<li><p>Health Clinic, where the total wellbeing is <span
class="math inline">6 + 8 + 4 = 18</span>.</p></li>
</ol></li>
<li><p>On the other hand, the <em>Rawlsian maximin</em> rule prioritizes
the least fortunate person’s well-being. It would rank the proposals
according to how the person who benefits the least fares in each
scenario. Using the maximin rule, the system would rank the proposals in
this order:</p>
<ol>
<li><p>Education Program, where Cara is worst off with a wellbeing of
5.</p></li>
<li><p>Health Clinic, where Cara is worst off with a wellbeing of
4.</p></li>
<li><p>Green Park, where Ana is worst off with a wellbeing of
3.</p></li>
</ol></li>
</ol>
<h4
id="deciding-on-a-social-welfare-function-is-important-for-clear-decision-making.">Deciding
on a social welfare function is important for clear
decision-making.</h4>
<p>The choice of social welfare function provides a structured
quantitative approach to decisions that can impact everyone. It sets a
benchmark for decision-makers, like our hypothetical AI in city
planning, to optimize collective welfare in a way that is transparent
and justifiable. When we have a framework to quantify society’s
wellbeing, we can use it to inform decisions about allocating resources,
planning for the future, or managing risks, among other things.</p>
<h4
id="social-welfare-functions-can-help-us-guide-and-train-present-day-ai.">Social
welfare functions can help us guide and train present-day AI.</h4>
<p>By measuring social wellbeing, we can determine which actions are
better or worse for society. This is a powerful measure to have in the
context of AI in various ways. While training AI, we can use social
welfare functions as the basis for reward signals that AI optimize for.
This would encourage AI to make decisions likely to increase overall
societal welfare. Moreover, social welfare functions offer us a
transparent and quantitative way to evaluate AI systems. These functions
can be used as metrics to judge how well an AI system is performing in
terms of contributing to societal welfare. For instance, we can evaluate
the city-planning AI’s recommendations by how well they align with a
chosen social welfare function. This offers a clear, objective standard
against which we can measure AI decisions. In sum, social welfare
functions serve as a useful tool for both training and evaluating AI,
enabling us to deploy AI systems that improve society.</p>
<h4
id="some-advanced-ai-systems-might-explicitly-maximize-social-welfare-functions.">Some
advanced AI systems might explicitly maximize social welfare
functions.</h4>
<p>Social welfare functions can serve as <em>utility functions</em> to
be optimized. Agents like AI will likely act to maximize utility
according to their utility function, so our choice of the utility
function is critical. If we set a social welfare function as the utility
function, it gives the AI a clear goal: to maximize societal welfare.
The AI can then base its decision-making process on this objective.
Notably, an AI system with such a utility function can effectively align
its preferences with the interests of society. As the AI makes decisions
or takes actions, it will strive to maximize the value of the social
welfare function, which represents the overall welfare of society. For
example, if an advanced AI is in charge of managing energy resources in
a city, it could allocate resources in a way that maximizes the chosen
social welfare function, promoting the greatest good for society. Thus,
social welfare functions can guide advanced AI to make decisions that
better serve societal interests, helping us navigate the challenges of
AI safety and risk.</p>
<h2 id="measuring-social-welfare"> 6.7.1 Measuring Social Welfare</h2>
<p><strong>Overview.</strong> In this section, we will consider how
social welfare functions work. We’ll use our earlier city planning
scenario as a reference to understand the fundamental properties of
social welfare functions. We will discuss how social welfare functions
help us compare different outcomes and the limitations of such
comparisons. Lastly, we’ll touch on ordinal social welfare functions,
why they might be insufficient for our purposes, and how using
additional information can give us a more holistic approach to
determining social welfare.</p>
<h4
id="social-welfare-functions-take-the-total-welfare-distribution-as-an-input-and-give-us-a-value-of-that-distribution-as-an-output.">Social
welfare functions take the total welfare distribution as an input and
give us a value of that distribution as an output.</h4>
<p>We can use the city planning example above to consider the basic
properties of social welfare functions. The input to a social welfare
function is a vector of individuals’ wellbeing values: for instance,
after the construction of a health clinic, the wellbeing vector of the
society composed of Ana, Ben, and Cara would be<br />
<span
class="math display"><em>W</em><sub><em>H</em></sub> = (6, 8, 4).</span></p>
<p>which tells us that three individuals have wellbeing levels equal to
seven, eight, and six. The social welfare function is a rule of what to
do with this input vector to give us one measure of how well off this
society is.</p>
<h4
id="the-function-applies-a-certain-rule-to-the-input-vector-to-generate-its-output.">The
function applies a certain rule to the input vector to generate its
output.</h4>
<p>We can apply many possible rules to a vector of numbers quantifying
wellbeing that can generate one measure of overall wellbeing. To
illustrate, we can consider the utilitarian social welfare function,
which implements a straightforward rule: adding up all the individual
wellbeing values. In the case of our three-person community, we saw that
the social welfare function would add 6, 8, and 4, giving an overall
social welfare of 18. However, social welfare functions can be defined
in numerous ways, offering different perspectives on aggregating
individual wellbeing. We will later examine continuous prioritarian
functions, which emphasize improving lower values of wellbeing. Other
social welfare functions might emphasize equality by penalizing high
disparities in wellbeing. These different functions reflect different
approaches to understanding and quantifying societal wellbeing.</p>
<h4
id="social-welfare-functions-help-us-compare-outcomes-but-only-within-one-function.">Social
welfare functions help us compare outcomes, but only within one
function.</h4>
<p>The basic feature of social welfare functions is that a higher output
value signifies more societal welfare. In our example, a total welfare
score of 20 would indicate a society that is better off than one with a
score of 18. However, it’s important to remember that the values
provided by different social welfare functions are not directly
comparable. A score of 20 from a utilitarian function, for instance,
does not correspond to the same level of societal wellbeing as a 20 from
a Rawlsian minimax social welfare function, since they apply different
rules to the wellbeing vector. Each function carries its own definition
of societal wellbeing, and the choice of social welfare function plays a
crucial role in shaping what we perceive as a better or worse society.
By understanding these aspects, we can more effectively utilize social
welfare functions as guideposts for AI behavior and decision-making,
aligning AI’s actions with our societal values.</p>
<h4
id="some-social-welfare-functions-might-just-need-a-list-ranking-the-different-choices.">Some
social welfare functions might just need a list ranking the different
choices.</h4>
<p>Sometimes, we might not need exact numerical values for each person’s
wellbeing to make the best decision. Think of a simple social welfare
function that only requires individuals to rank their preferred options.
For example, three people could rank their favorite fruits in the order
“apple, banana, cherry”. From this, we learn that everyone prefers
apples over cherries, but we don’t know by how much they prefer apples.
This level of detail might be enough for some decisions: clearly, we
should give them apples instead of cherries! Such a social welfare
function won’t provide exact measures of societal wellbeing, but it will
give us a ranked list of societal states based on everyone’s
preferences.</p>
<h4
id="voting-is-a-typical-example-of-an-ordinal-social-welfare-function.">Voting
is a typical example of an ordinal social welfare function.</h4>
<p>Instead of trying to estimate each person’s potential wellbeing for
each option, the city planning committee might ask everyone to vote for
their top choice. We assume that each person votes for the option they
believe will enhance their wellbeing most. This relates to the
<em>Preference View of Wellbeing</em>, which says that individuals know
what’s best for them, and their choices reflect their wellbeing. Through
this voting process, we can create a list ranking the options by the
number of votes each one received, even if we don’t assign specific
numerical values to each option—this is ordinal information, where all
we know are the rankings.<br />
As an illustration, if most people vote for the park, that indicates the
park might contribute the most to overall wellbeing, according to this
social welfare function. The function would look at the number of votes
for each option, and the one with the most votes would be deemed the
best choice. This is a simpler approach than calculating everyone’s
wellbeing for each option, so it’s less likely to lead to errors.
However, this type of social welfare function does have its own
challenges, such as the problem highlighted by Arrow’s Impossibility
Theorem.</p>
<h4
id="arrows-impossibility-theorem-is-one-reason-we-might-want-more-than-ordinal-information.">Arrow’s
impossibility theorem is one reason we might want more than ordinal
information.</h4>
<p>In our city planning scenario, Ana would vote for the Education
Program, Ben would vote for the Health Clinic, and Cara would vote for
the Green Park. If we tried to aggregate these rankings without any
additional information, such as the numerical scores assigned to each
option, we would not have any reason to choose one option over the
other. This is an example of a general problem: Arrow’s Impossibility
Theorem. In essence, it suggests it’s impossible to create a perfect
voting system that fulfills a set of reasonable criteria while only
using ordinal information. These criteria involve metrics of fairness
like “non-dictatorships” and coherency like “if everyone prefers apples
to cherries, then the social welfare function prefers apples to
cherries”. Adding information about the strength of preferences is one
solution to Arrow’s Impossibility Theorem. Additionally, if we have
access to such information, using it will mean that we arrive at better
answers. Next, we will consider two classes of social welfare functions
that use such information: utilitarian and prioritarian social welfare
functions.</p>
<h3 id="utilitarian-social-welfare-functions">Utilitarian Social Welfare
Functions</h3>
<h4 id="overview.-4">Overview.</h4>
<p>This section is focused on utilitarian social welfare
functions-—functions that sum up individual wellbeing to calculate
social welfare, in line with the utilitarian theory of morality. We’ll
start by exploring cost-benefit analysis, a common social welfare
function that draws inspiration from utilitarian reasoning, through the
example of a decision to build a health clinic. While cost-benefit
analysis provides a convenient and quantitative approach to
decision-making, we’ll discuss its limitations in capturing the full
ideas of wellbeing. Further, we’ll consider how utilitarian social
welfare functions can foster equity, especially when diminishing returns
of resources are considered and how AI systems, optimized using these
functions, could potentially improve inequality. Lastly, we’ll discuss
how the utilitarian social welfare function, under certain assumptions,
is the only method that satisfies key decision-making criteria.</p>
<h4
id="cost-benefit-analysis-is-a-popular-but-crude-approximation-of-utilitarian-social-welfare.">Cost-benefit
analysis is a popular but crude approximation of utilitarian social
welfare.</h4>
<p>Governments and other decision-makers often use cost-benefit analysis
to ground their decision-making quantitatively. Simply, this involves
adding up the expected benefits of an action or a decision and comparing
it to the anticipated costs. We can apply this to whether to build a
health clinic that’ll operate for 10 years. If the benefits outweigh the
costs over the considered time span, the committee may decide to proceed
with building the clinic.<br />
This method allows the government to assess multiple options and choose
the one with the highest net benefit. By doing so, it approximates
utilitarian social welfare. For the health clinic, the committee assigns
monetary values to each improvement and then multiplies this by the
number of people affected by the improvement. In essence, cost-benefit
analysis assumes that wellbeing can be approximated by financial losses
and gains and considers the sum of monetary benefits instead of the sum
of wellbeing values. Using monetary units simplifies comparison and
limits the range of factors it can consider.</p>
<h4
id="cost-benefit-analysis-is-not-a-perfect-representation-of-utilitarian-social-welfare.">Cost-benefit
analysis is not a perfect representation of utilitarian social
welfare.</h4>
<p>Money is not a complete measure of wellbeing. While money is easy to
quantify, it doesn’t capture all aspects of wellbeing. For instance, it
might not fully account for the psychological comfort a local health
clinic provides to a community. Additionally, providing income to five
doctors who are already high earners might be less important than
employing 20 support staff, even though both benefits sum to $5,000,000
over the ten years. Cost-benefit analysis lacks this fine-grained
consideration of wellbeing. AI systems could, in theory, maximize social
welfare functions, considering a broader set of factors that contribute
to wellbeing. However, we largely rely on cost-benefit analysis today,
focusing on financial measures, to guide our decisions. This brings us
to the challenge of improving this method or finding alternatives to
better approximate utilitarian social welfare in real-world
decision-making, including those involving AI systems. Utilitarian
social welfare functions would promote some level of equity. Usually,
additional resources are less valuable when we already have a lot of
them. This is diminishing marginal returns: the benefit from additional
food, for instance, is very high when we have no food but very low when
we already have more than we can eat. Extending this provides an
argument for a more equitable distribution of resources under
utilitarian reasoning. Consider taxation: if one individual has a
surplus of wealth, say a billion dollars, and another has only one
dollar, redistributing a few dollars from the wealthy individual to the
less fortunate one may elevate overall societal wellbeing. This is
because the added value of a dollar to the less fortunate individual is
likely very high, allowing them to purchase necessities like food and
shelter, whereas it is likely very low for the wealthy individual.</p>
<h4
id="ai-systems-optimizing-utilitarian-social-welfare-functions-might-therefore-improve-inequality.">AI
systems optimizing utilitarian social welfare functions might therefore
improve inequality.</h4>
<p>Utilitarian AI systems might recognize the diminishing returns of
resource accumulation, leading them to suggest policies that lead to a
more equal distribution of resources. It is important to remember that
the utilitarian has no objection to inequality, except that those with
less can better use resources than those who are already happy. This
counters a frequent critique that utilitarianism neglects inequality.
Current methods like cost-benefit analysis may not fully capture this
aspect. Therefore, AI guided by a utilitarian social welfare function
might propose approaches for a more equitable distribution of resources
that conventional methods could overlook.</p>
<h4
id="a-utilitarian-social-welfare-function-is-the-only-way-to-satisfy-some-basic-requirements.">A
utilitarian social welfare function is the only way to satisfy some
basic requirements.</h4>
<p>Let us reconsider the city planning committee deciding what to build
for Ana, Ben, and Cara. If they all have the same level of wellbeing
whether a new Education Program or a Green Park is built, then it seems
right that the city’s planning committee shouldn’t favor one over the
other. Suppose we changed the scenario a bit. Suppose Ana benefits more
from a Health Clinic than an Education Program, and Ben and Cara don’t
have a strong preference either way. It now seems appropriate that the
committee should favor building the Health Clinic.</p>
<h4 id="harsanyis-social-aggregation-theorem.">Harsanyi’s Social
Aggregation Theorem.</h4>
<p>Harsanyi showed that—assuming the individuals are rational, in the
sense of maximizing expected utility—if we want our social welfare
function to make choices like this consistently, we need to use a model
where we add up everyone’s wellbeing <span class="citation"
data-cites="weymark1993harsanyi"></span>. This is the foundation of a
utilitarian social welfare function. Harsanyi’s aggregation theorem
proved that it is the only kind of social welfare function that always
is indifferent between options if everyone is equally happy with them
and favors the option that makes someone better off, as long as it
doesn’t make anyone worse off. This has been seen as a compelling reason
to pick utilitarian social welfare functions over other ones.</p>
<h3 id="prioritarian-social-welfare-functions">Prioritarian Social
Welfare Functions</h3>
<p><strong>Overview.</strong> In this section, we will consider
prioritarian social welfare functions and how they exhibit differing
degrees of concern for the wellbeing of various individuals. We will
start by describing prioritarian social welfare functions, which give
extra weight to the wellbeing of worse-off people. This discussion will
include some common misconceptions about prioritarianism and how it
contrasts with utilitarianism in resource allocation. We will focus on
two types of prioritarian functions: the Rawlsian minimax social welfare
function and continuous prioritarian functions.</p>
<h4
id="there-are-two-common-misunderstandings-about-prioritarian-social-welfare-functions.">There
are two common misunderstandings about prioritarian social welfare
functions.</h4>
<p>Firstly, prioritarians are not focused on reducing inequality itself,
unlike egalitarians. Their main goal is to increase the wellbeing of
those who need it most. They think giving an extra unit of wellbeing to
someone with less is more valuable than giving it to someone already
well-off. The level of inequality in a society doesn’t affect their
measure of social welfare, and reducing inequality isn’t their goal
unless it improves individual wellbeing. Secondly, prioritarians are not
driven by the belief that it’s easier to improve the wellbeing of the
worst off. They would rather see benefits go to the worse off even if it
costs the same as improving the lives of those who are better off. This
also sets them apart from utilitarians, who might typically help the
worst off because they see more value due to diminishing marginal
utility. The prioritarian approach isn’t about the efficiency of
resources but about focusing resources on those who need them most.
Thus, while utilitarian and prioritarian social welfare functions aim
for a better society, they have distinct ways of achieving this
goal.</p>
<h4
id="a-special-case-of-prioritarian-social-welfare-functions-is-the-rawlsian-maximin-function.">A
special case of prioritarian social welfare functions is the Rawlsian
“maximin” function.</h4>
<p>The Rawlsian social welfare function takes the idea of protecting the
worse off to the extreme: social welfare is simply the lowest welfare of
anyone in society. It is called the “<em>maximin</em>” function because
it seeks to maximize the minimum wellbeing, or in other words, to ensure
that the worst-off individual is as well off as possible. When we
applied the maximin function to the city planning committee, it decided
that the worst option was the Green Park, despite the utilitarian social
welfare function determining that was the best one. Using the maximin
principle here, we want to go with the choice to ensure the worst-off
person is as happy as possible. When we look at the least happy person
for each option, we see that for the Health Clinic it’s 6 (Cara), for
the Education Program it’s 5 (Cara), and for the Green Park it’s 4
(Ana). So, if we follow the maximin rule, the committee would choose the
Health Clinic because it would bring up the wellbeing of the person
doing the worst. This way, we ensure we’re looking out for the people
who need it most.<br />
However, this maximin approach has its own problems, like the “grouch”
issue. This is when someone always rates their wellbeing low, no matter
what. If we’re always looking out for the worst-off person, we might end
up always catering to the grouch, even though their low score might not
be due to real hardship. It’s important to remember this when
considering how to use the Rawlsian maximin approach.</p>
<h4
id="continuous-prioritarian-social-welfare-functions-offer-a-middle-ground.">Continuous
prioritarian social welfare functions offer a middle ground.</h4>
<p>We might want our social welfare function to account for both the
positive effects of increasing anyone’s welfare and the extra positive
effects of increasing the welfare of someone who isn’t doing well. This
is the tradeoff between efficiency and equity. Many social welfare
functions embrace prioritarian principles without going to the extreme
of the maximin function’s concern for equity. This can be achieved using
a social welfare function that shows diminishing returns relative to
individual welfare: the boost it gives to social welfare when any
individual’s wellbeing improves is larger if that person initially had
less wellbeing. For example, we could use the <em>logarithmic social
welfare function</em><br />
<span
class="math display"><em>W</em>(<em>w</em><sub>1</sub>,<em>w</em><sub>2</sub>,...,<em>w</em><sub><em>n</em></sub>) = log <em>w</em><sub>1</sub> + log <em>w</em><sub>2</sub> + ... + log <em>w</em><sub><em>n</em></sub>,</span>
where <span class="math inline"><em>W</em></span> is the social welfare
and each <span class="math inline"><em>w</em><sub>1</sub></span>,<span
class="math inline"><em>w</em><sub>2</sub></span>,...,<span
class="math inline"><em>w</em><sub><em>n</em></sub></span> are the
individual wellbeing values of everyone in society. The logarithmic
social welfare function is (ordinally) equivalent to the Bernoulli-Nash
social welfare function, which is the product of wellbeing values.<br />
Suppose there are three individuals with wellbeing 2, 4, and 16 and we
are using log base 2. Social welfare is<br />
<span
class="math display"><em>W</em>(2, 4, 16) = log<sub>2</sub>(2) + log<sub>2</sub>(4) + log<sub>2</sub>(16) = 1 + 2 + 4 = 7.</span></p>
<p>Compare the following two changes: increasing someone from 2 to 4 or
increasing someone from 4 to 8. The first change results in<br />
<span
class="math display"><em>W</em>(4, 4, 16) = log<sub>2</sub>(4) + log<sub>2</sub>(4) + log<sub>2</sub>(16) = 2 + 2 + 4 = 8.</span>
The second change results in<br />
<span
class="math display"><em>W</em>(2, 8, 16) = log<sub>2</sub>(2) + log<sub>2</sub>(8) + log<sub>2</sub>(16) = 1 + 3 + 4 = 8.</span></p>
<p>Even though the second change is larger, social welfare is increased
by the same amount as when improving the wellbeing of the individual who
was worse off by a smaller amount. This highlights the principle that
improving anyone’s welfare is beneficial, and it’s easier to increase
social welfare by improving the welfare of those who are worse off.
Additionally, even though the second change doesn’t affect the worst
off, the social welfare function shows society is better off. This
approach allows us to consider both the overall level of wellbeing and
its distribution.</p>
<h4 id="we-can-specify-exactly-how-prioritarian-we-are.">We can specify
exactly how prioritarian we are.</h4>
<p>Let the parameter <span class="math inline"><em>γ</em></span>
represent the degree of priority we give worse-off individuals. We can
link the Rawlsian maximin, logarithmic, and utilitarian social welfare
functions by using the isoelastic social welfare function<br />
<span class="math display">$$W(w_1, w_2, ..., w_n) =
\frac{1}{1-\gamma}\left(w_1^{1-\gamma} + w_2^{1 - \gamma} + ... +
w_n^{1-\gamma}\right).$$</span></p>
<p>If we think we should give no priority to the worse-off, then we can
set <span class="math inline"><em>γ</em> = 0</span>: the entire equation
is then just a sum of welfare levels, which is the utilitarian social
welfare function. By contrast, if we were maximally prioriarian, taking
the limit of <span class="math inline"><em>γ</em></span> as it gets
infinitely large, then we recover Rawls’ maximin function. Similarly, if
we took the limit of <span class="math inline"><em>γ</em></span> as it
approached 1, we would recover the logarithmic social welfare function.
This function is widespread in economic literature due to this
versatility; among other things, it allows researchers to determine from
observed preferences what a typical person’s parameter <span
class="math inline"><em>γ</em></span> is. By adopting this most general
form, we can pick exactly how we want to prioritize individuals in
society. This enables a principled way of trading off efficiency and
equity.</p>
<h3 id="conclusions-about-social-welfare-functions">Conclusions About
Social Welfare Functions</h3>
<h4 id="using-ai-to-estimate-social-welfare.">Using AI to estimate
social welfare.</h4>
<p>Artificial intelligence might be used to estimate the inputs and
calculate the outputs of social welfare functions to help us decide
between different actions and implement our ideal decision processes. By
processing large amounts of data, AI systems might be able to predict
individual welfare under various scenarios, paving the way for more
informed decision-making. It has been demonstrated, for instance, that
context-aware machine learning models like large language models can be
used for predicting disease incidence faster than conventional
epidemiological methods, which can be used to evaluate different public
health proposals from a social welfare perspective. The application of
AI can lead to more refined estimates of social welfare.</p>
<h4 id="using-social-welfare-functions-to-train-ai.">Using social
welfare functions to train AI.</h4>
<p>A second connection between social welfare functions and AI lies in
creating AI systems. We can shape AI systems to generally promote social
welfare, ensuring they are aligned with human interests even when
optimizing for distinct goals, such as corporate profit. Particularly in
reinforcement learning, where decision-making is based on rewards or
penalties, these can be tethered to societal wellbeing. Even for other
agents, AI behavior can be guided towards promoting social welfare,
aligning AI performance with societal wellbeing and making AI a
compelling tool for social good.</p>
<h4 id="using-ai-to-maximize-social-welfare.">Using AI to maximize
social welfare.</h4>
<p>Beyond creating AI systems in line with social welfare, we can steer
advanced AI to actively optimize social wellbeing by using social
welfare functions as their objective functions. This harnesses AI’s
power to promote societal welfare effectively. Given AI’s data
processing and predictive capabilities, it can evaluate various
strategies to identify what would best increase social welfare. By
aligning AI objectives with social welfare functions, we can develop
beneficial AI systems that not only recognize and understand social
wellbeing but also actively work towards enhancing it. This proactive
use of AI bolsters our ability to build societies where individual
wellbeing is optimized and evenly distributed, reflecting our social
preferences.</p>
<h4 id="challenges">Challenges</h4>
<p>Defining an accurate and comprehensive social welfare function that
takes into account the diverse and often conflicting interests and
values of a society may be challenging. Different stakeholders may have
varying definitions of what constitutes social welfare or how they would
resolve trade-offs between different values, and reaching a consensus
could be difficult. AI systems trained to maximise social welfare may
also inherit various problems of current models such as vulnerability to
adversarial attacks and proxy gaming and difficulties in interpreting
the internal logic that led them to make certain decisions (both
discussed in the Single Agent Safety chapter),</p>
<h4 id="summary.-7">Summary.</h4>
<p>In this section, we discussed social welfare functions: mathematical
functions that tell us how to aggregate information about individual
welfare into one society-wide measure. We considered why social welfare
functions might be relevant in the context of decision making by
beneficial AI systems and explored a few properties that all social
welfare functions possess. We analyzed how governments today use cost
benefit analysis as an approximation to social welfare functions and why
that falls short of what we desire. The main point of this section was
to document and understand some of the most common social welfare
functions—-the utilitarian function, the Rawlsian maximin function, and
continuous prioritarian functions-—and how they differ in their levels
of concern for the well-being of different individuals, and can be
represented within the framework of a general isoelastic social welfare
function.<br />
We think that the use of AI can help estimate social welfare inputs and
calculate outputs, and AI systems can be shaped to generally promote
social welfare and actively optimize it using social welfare functions
as objective functions. Ultimately, the proactive use of AI bolsters our
ability to build societies where individual well-being is both optimized
and evenly distributed, reflecting our social preferences.<br />
</p>
