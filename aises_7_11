<!-- Normative Ethics -->

<h1 id="introduction">7.1 Introduction</h1>
<p>Ethics is the branch of philosophy concerned with questions of right
and wrong, good and bad, and how we ought to live our lives. We make
ethical choices every day. When we decide whether to tell the truth or
lie, help someone in need or ignore them, treat others with respect or
act in a discriminatory manner, we are making moral decisions that
reflect our values, beliefs, and moral principles. Philosophical ethics
seeks to provide a systematic framework for making these
decisions.<p>
In this chapter, we will explore some of the key concepts and theories
in philosophical ethics. This branch of research is also commonly called
<em>moral philosophy</em>. We use the terms <em>ethics</em> and
<em>morality</em> interchangeably. The subfield of ethics dedicated to
developing moral theories is called normative ethics. Normative ethics
is the consideration of questions like “Which actions are right and
wrong?”<p>
This chapter outlines some of the main reasons why it’s important for AI
researchers to learn about ethics. We then turn to the basic building
blocks of moral theories, examining various moral considerations like
intrinsic goods, constraints, and special obligations. Then we will
explore some of the most prominent ethical theories, like
utilitarianism, deontology, and virtue ethics, evaluating their
strengths and weaknesses. Finally, we consider how we might deal with
reasonable disagreement over what is right and wrong. Throughout, our
key focus is on the ethical concepts that are most relevant to the
development, implementation, and governance of AI.</p>
