<h1 id="conclusion">Conclusion</h1>
<p>In the introduction, we laid out the purpose of this chapter:
understanding the fundamentals of how to govern AI. In other words, we
wanted to understand how to organize, manage, and steer the development
and deployment of AI technologies using an array of tools including
norms, policies, and institutions. To set the scene, we considered a set
of actors and tools that governance needs to consider.</p>
<p><strong>Takeoff.</strong> We explored potential scenarios for
advanced AI takeoff. There is serious uncertainty regarding when these
transformative AIs will arise and whether progress will follow
continuous trends or exhibit abrupt, discontinuous jumps in
capabilities. However, once they emerge, advanced AIs would likely
massively accelerate technological advancement and economic growth. This
acceleration could profoundly reshape human civilization, potentially
within a short timeframe. Careful governance, informed by answers to
questions about how AI development will progress, will be essential for
steering it in broadly positive directions that benefit humanity.</p>
<p><strong>Distribution.</strong> We then explored three key dimensions
around which the impacts of advanced AI systems may be distributed:
power among AIs, access to AIs, and costs/benefits of AIs. First, in
terms of distributing power among AIs, concentrating capabilities and
control in a single AI or small group of AIs poses risks like
permanently locking in certain values or goals. However, distributing
power more widely among a large, diverse ecosystem of AIs also has
downsides, like increasing the potential for misuse or making it more
difficult to correct AI systems that begin behaving undesirably.<p>
Second, regarding access to AIs, it is unclear whether availability
should be tightly restricted or widely open to the general public.
Limiting access risks misuse by powerful groups whereas open access
risks misuse by malicious actors. Third, equitable distribution of the
economic and social impacts of AI will be crucial, including dealing
with potential technologically-induced unemployment while ensuring that
productivity gains are shared broadly rather than accruing only to a
small group like AI developers and investors. Distributing these three
key aspects of advanced AI fairly will require thoughtful
governance.</p>
<p><strong>Compute Governance.</strong> Next, we explored how governing
access to and use of the computing resources that enable AI development
could provide an important lever for influencing the trajectory of AI
progress. Compute is an indispensable input to developing advanced AI
capabilities. It also has properties like physicality, excludability,
and quantifiability that make governing it more feasible than other
inputs like data and algorithms. Compute governance can allow control
over who is granted access to what levels of computational capabilities,
controlling who can create advanced AIs. It also facilitates setting and
enforcing safety standards for how compute can be used, enabling the
steering of AI development.</p>
<p><strong>Corporate Governance.</strong> At the organizational level,
we discussed how aspects of corporate structure and governance like
legal form, ownership models, policies, practices, and assurance
mechanisms can help steer technology companies away from solely
maximizing profits and shareholder value. Instead, they can guide
corporate AI work in directions that prioritize broader societal
interests like safety, fairness, privacy, and ethics. However, achieving
this through corporate governance alone may prove challenging, making
complementary approaches at other levels vital.</p>
<p><strong>National Governance.</strong> For governance at the national
level, we explored policy tools governments can use to align AI
development with public interests, both in the public and private
sectors. These included safety regulations, liability rules that make AI
developers internalize potential damages, investments to improve
societal resilience against AI risks, and measures for maintaining
national competitiveness in AI while still ensuring domestic safety.
Combinations of these policy mechanisms can help nations steer AI
progress in their jurisdictions towards beneficial ends.</p>
<p><strong>International Governance.</strong> At the international
level, governance of AI systems is made challenging by issues like
verifying adherence to agreements. However, international cooperation is
essential for managing risks from AI and distributing benefits globally.
Approaches like international safety standards for civilian AI
applications, agreements to limit military uses of AI, and proposals for
concentrating advanced AI development within select transnational
groups, may all help promote global flourishing. A lack of any
meaningful international governance could lead to a dangerous spiral of
competitive dynamics and erosion of safety standards.</p>
<p><strong>Conclusion.</strong> This chapter provides an overview of a
diverse selection of governance solutions spanning from policies within
technology firms to agreements between nations in global institutions.
The arrival of transformative AI systems will require thoughtful
governance at multiple levels in order to steer uncertain technological
trajectories in broadly beneficial directions aligned with humanityâ€™s
overarching interests. The deliberate implementation of policies,
incentives and oversight will be essential to realizing the potential of
AI to improve human civilization rather than destroy it.</p>
